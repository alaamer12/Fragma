{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìò Notebook: 03_modeling_and_evaluation.ipynb\n",
        "_**Part of the Fragma IPython Notebook Project Series**_\n",
        "\n",
        "*Focused on developing and evaluating machine learning models for fragment detection.*\n",
        "\n",
        "---\n",
        "\n",
        "## üß≠ Table of Contents\n",
        "\n",
        "1. [üìò Overview & Navigation](#overview)\n",
        "2. [üß† Context & Purpose](#context)\n",
        "3. [üß© Main Components](#components)\n",
        "4. [üß≠ Notebook Structure](#notebooks)\n",
        "5. [üì¶ Dependencies](#dependencies)\n",
        "6. [üõ†Ô∏è Config & Setup](#setup)\n",
        "7. [üìä Model Pipeline](#pipeline)\n",
        "8. [üìà Evaluation & Results](#results)\n",
        "9. [üìö Resources](#resources)\n",
        "10. [üë• Contributors](#team)\n",
        "\n",
        "> **Quick Links:** [üè† Home](#overview) | [üîÑ Status](#notebooks) | [üìö Docs](#resources)\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ Overview & Navigation\n",
        "\n",
        "This notebook represents the final stage in our fragment detection pipeline, focusing on model development and evaluation.\n",
        "It provides: **A comprehensive machine learning pipeline using TF-IDF vectorization, Random Forest classification, and PSO-based hyperparameter optimization.**\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Context & Purpose\n",
        "\n",
        "**üéØ Purpose:**  \n",
        "To develop and evaluate a robust machine learning model for detecting sentence fragments, combining both text-based and structural features.\n",
        "\n",
        "**üéØ Objectives:**  \n",
        "- Develop an effective text vectorization strategy\n",
        "- Build a hybrid model combining text and structural features\n",
        "- Optimize model performance using PSO\n",
        "- Evaluate and analyze model performance\n",
        "- Visualize feature importance and results\n",
        "\n",
        "**üìò Context:**  \n",
        "This notebook builds upon the preprocessed data from notebook 02, utilizing both the cleaned text and extracted linguistic features to create a powerful fragment detection model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß© Main Components\n",
        "\n",
        "### `TextVectorizer`\n",
        "> TF-IDF based text vectorization with optimized parameters.\n",
        "\n",
        "```python\n",
        "vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
        "# Returns: Sparse matrix of TF-IDF features\n",
        "```\n",
        "\n",
        "### `ModelPipeline`\n",
        "> Comprehensive pipeline combining text and structural features.\n",
        "\n",
        "```python\n",
        "pipeline = Pipeline([\n",
        "    ('features', ColumnTransformer([\n",
        "        ('text', TfidfVectorizer(), text_col),\n",
        "        ('struct', 'passthrough', structured_cols)\n",
        "    ])),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])\n",
        "```\n",
        "\n",
        "### `PSOOptimizer`\n",
        "> Particle Swarm Optimization for hyperparameter tuning.\n",
        "\n",
        "```python\n",
        "best_params = optimize_hyperparameters(pipeline, param_space)\n",
        "# Returns: Optimized hyperparameters with cross-validation\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Model Features\n",
        "\n",
        "### 1. Text Features (TF-IDF)\n",
        "- **Word-Level Features**: Unigram and bigram frequencies\n",
        "- **Vectorization Parameters**: Optimized max_features and ngram_range\n",
        "- **Preprocessing**: Utilizes cleaned text from previous notebook\n",
        "\n",
        "### 2. Structural Features\n",
        "- **Linguistic Markers**: Auxiliary verbs, punctuation, conjunctions\n",
        "- **Grammatical Features**: Past verbs, gerunds, adverbs\n",
        "- **Syntactic Elements**: Sentence starters, capitalization\n",
        "\n",
        "### 3. Model Architecture\n",
        "- **Base Classifier**: Random Forest with optimized parameters\n",
        "- **Feature Fusion**: Combined text and structural features\n",
        "- **Hyperparameter Space**: Carefully selected parameter ranges\n",
        "\n",
        "### 4. Optimization\n",
        "- **PSO Algorithm**: Particle swarm optimization for tuning\n",
        "- **Cross-Validation**: K-fold validation during optimization\n",
        "- **Performance Metrics**: Accuracy, F1-score, precision, recall\n",
        "\n",
        "### 5. Visualization\n",
        "- **Feature Importance**: Random forest feature rankings\n",
        "- **Performance Curves**: ROC, precision-recall curves\n",
        "- **Error Analysis**: Confusion matrix and misclassification analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Dependencies\n",
        "\n",
        "```bash\n",
        "pandas         # Data manipulation\n",
        "numpy         # Numerical operations\n",
        "scikit-learn  # Machine learning tools\n",
        "pyswarms      # PSO implementation\n",
        "matplotlib    # Visualization\n",
        "seaborn      # Enhanced visualization\n",
        "joblib       # Model persistence\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß≠ Notebook Structure\n",
        "\n",
        "| üî¢ Order | üìì Notebook | üìù Description |\n",
        "|---------:|------------|----------------|\n",
        "| 0 | [00-Fragma-Overview.ipynb](https://colab.research.google.com/drive/1oUmSqBuPqv2gObJjhezXaa6xBxe_Tl4g?usp=sharing) | Project overview and setup |\n",
        "| 1 | [01-Fragment-DS-Generator.ipynb](https://colab.research.google.com/drive/1aAVCptdYyRHmytnY7O__anYKpZh5Hl-w?usp=sharing) | Dataset generation |\n",
        "| 2 | [02-Data-Preprocessing.ipynb](https://colab.research.google.com/drive/1QbVTz71jGvVvr2rXwJk9RKGKS4r1ntCC?usp=sharing) | Text preprocessing |\n",
        "| 3 | [03-Model-Development.ipynb](https://colab.research.google.com/drive/1CDwjXuqBj1LBdXXvvFymNh6etWNpUnth?usp=sharing) | Model training and evaluation (Current) |\n",
        "\n",
        "> ‚èÆ **Previous:** [02-Data-Preprocessing.ipynb](https://colab.research.google.com/drive/1QbVTz71jGvVvr2rXwJk9RKGKS4r1ntCC?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì• Inputs & Outputs\n",
        "\n",
        "**üì• Inputs:**\n",
        "- `processed_dataset.csv`: Preprocessed dataset with text and linguistic features\n",
        "  - Text column: 'Processed Text'\n",
        "  - Target column: 'is_fragment'\n",
        "  - Structural features: 17 binary linguistic markers\n",
        "\n",
        "**üì§ Outputs:**\n",
        "- Trained model with:\n",
        "  - Optimized TF-IDF vectorizer\n",
        "  - Tuned Random Forest classifier\n",
        "  - Feature importance rankings\n",
        "  - Performance metrics and visualizations\n",
        "  - Detailed error analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Model Pipeline Configuration\n",
        "\n",
        "The model pipeline is configured through several key components:\n",
        "\n",
        "### Text Vectorization Config\n",
        "```python\n",
        "TFIDF_CONFIG = {\n",
        "    \"max_features\": [1000, 2000, 3000],  # Features to consider\n",
        "    \"ngram_range\": [(1, 1), (1, 2)],    # N-gram lengths\n",
        "    \"min_df\": [2, 5],                    # Minimum document frequency\n",
        "    \"max_df\": [0.9, 0.95]               # Maximum document frequency\n",
        "}\n",
        "```\n",
        "\n",
        "### Random Forest Config\n",
        "```python\n",
        "RF_CONFIG = {\n",
        "    \"n_estimators\": [100, 200, 300],     # Number of trees\n",
        "    \"max_depth\": [10, 20, 30, None],     # Tree depth\n",
        "    \"min_samples_split\": [2, 5, 10],     # Minimum samples for split\n",
        "    \"min_samples_leaf\": [1, 2, 4]        # Minimum samples in leaf\n",
        "}\n",
        "```\n",
        "\n",
        "### PSO Configuration\n",
        "```python\n",
        "PSO_CONFIG = {\n",
        "    \"n_particles\": 30,          # Number of particles\n",
        "    \"dimensions\": 8,           # Number of parameters to optimize\n",
        "    \"iterations\": 50,          # Maximum iterations\n",
        "    \"cv_folds\": 5             # Cross-validation folds\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Evaluation Strategy\n",
        "\n",
        "### Data Splitting\n",
        "- Train set (70%): Model training and PSO optimization\n",
        "- Validation set (15%): Parameter selection and early stopping\n",
        "- Test set (15%): Final evaluation only\n",
        "\n",
        "### Performance Metrics\n",
        "1. **Primary Metrics**\n",
        "   - Accuracy: Overall correctness\n",
        "   - F1-Score: Harmonic mean of precision and recall\n",
        "   - ROC-AUC: Discrimination ability\n",
        "\n",
        "2. **Secondary Metrics**\n",
        "   - Precision: Positive predictive value\n",
        "   - Recall: True positive rate\n",
        "   - Confusion Matrix: Detailed error analysis\n",
        "\n",
        "3. **Cross-Validation**\n",
        "   - 5-fold stratified CV during optimization\n",
        "   - Mean and standard deviation of metrics\n",
        "\n",
        "### Feature Analysis\n",
        "- Random Forest feature importance rankings\n",
        "- TF-IDF term importance analysis\n",
        "- Feature correlation study\n",
        "\n",
        "### Error Analysis\n",
        "- Misclassification analysis by feature type\n",
        "- Length-based error patterns\n",
        "- Linguistic feature impact study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üë• Contributors\n",
        "\n",
        "| üë§ Name | üßë‚Äçüíª Role | üì¨ GitHub | üîó LinkedIn |\n",
        "|---------|----------|-----------|------------|\n",
        "| Amr Muhamed | Maintainer | [alaamer12](https://github.com/alaamer12) | [alaamer12](https://linkedin.com/in/alaamer12) |\n",
        "\n",
        "¬© 2025 Amr Muhamed. All Rights Reserved.\n",
        "\n",
        "*Last updated: May 13, 2025*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
